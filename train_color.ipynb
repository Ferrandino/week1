{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    }
   ],
   "source": [
    "#load in modile net with top layer removed and add 4 more layers\n",
    "base_model=MobileNet(weights='imagenet',include_top=False) #imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n",
    "x=Dense(1024,activation='relu')(x) #dense layer 2\n",
    "x=Dense(512,activation='relu')(x) #dense layer 3\n",
    "preds=Dense(9,activation='softmax')(x) #final layer with softmax activation change to number of categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=base_model.input,outputs=preds)\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1_pad\n",
      "2 conv1\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 conv_dw_1\n",
      "6 conv_dw_1_bn\n",
      "7 conv_dw_1_relu\n",
      "8 conv_pw_1\n",
      "9 conv_pw_1_bn\n",
      "10 conv_pw_1_relu\n",
      "11 conv_pad_2\n",
      "12 conv_dw_2\n",
      "13 conv_dw_2_bn\n",
      "14 conv_dw_2_relu\n",
      "15 conv_pw_2\n",
      "16 conv_pw_2_bn\n",
      "17 conv_pw_2_relu\n",
      "18 conv_dw_3\n",
      "19 conv_dw_3_bn\n",
      "20 conv_dw_3_relu\n",
      "21 conv_pw_3\n",
      "22 conv_pw_3_bn\n",
      "23 conv_pw_3_relu\n",
      "24 conv_pad_4\n",
      "25 conv_dw_4\n",
      "26 conv_dw_4_bn\n",
      "27 conv_dw_4_relu\n",
      "28 conv_pw_4\n",
      "29 conv_pw_4_bn\n",
      "30 conv_pw_4_relu\n",
      "31 conv_dw_5\n",
      "32 conv_dw_5_bn\n",
      "33 conv_dw_5_relu\n",
      "34 conv_pw_5\n",
      "35 conv_pw_5_bn\n",
      "36 conv_pw_5_relu\n",
      "37 conv_pad_6\n",
      "38 conv_dw_6\n",
      "39 conv_dw_6_bn\n",
      "40 conv_dw_6_relu\n",
      "41 conv_pw_6\n",
      "42 conv_pw_6_bn\n",
      "43 conv_pw_6_relu\n",
      "44 conv_dw_7\n",
      "45 conv_dw_7_bn\n",
      "46 conv_dw_7_relu\n",
      "47 conv_pw_7\n",
      "48 conv_pw_7_bn\n",
      "49 conv_pw_7_relu\n",
      "50 conv_dw_8\n",
      "51 conv_dw_8_bn\n",
      "52 conv_dw_8_relu\n",
      "53 conv_pw_8\n",
      "54 conv_pw_8_bn\n",
      "55 conv_pw_8_relu\n",
      "56 conv_dw_9\n",
      "57 conv_dw_9_bn\n",
      "58 conv_dw_9_relu\n",
      "59 conv_pw_9\n",
      "60 conv_pw_9_bn\n",
      "61 conv_pw_9_relu\n",
      "62 conv_dw_10\n",
      "63 conv_dw_10_bn\n",
      "64 conv_dw_10_relu\n",
      "65 conv_pw_10\n",
      "66 conv_pw_10_bn\n",
      "67 conv_pw_10_relu\n",
      "68 conv_dw_11\n",
      "69 conv_dw_11_bn\n",
      "70 conv_dw_11_relu\n",
      "71 conv_pw_11\n",
      "72 conv_pw_11_bn\n",
      "73 conv_pw_11_relu\n",
      "74 conv_pad_12\n",
      "75 conv_dw_12\n",
      "76 conv_dw_12_bn\n",
      "77 conv_dw_12_relu\n",
      "78 conv_pw_12\n",
      "79 conv_pw_12_bn\n",
      "80 conv_pw_12_relu\n",
      "81 conv_dw_13\n",
      "82 conv_dw_13_bn\n",
      "83 conv_dw_13_relu\n",
      "84 conv_pw_13\n",
      "85 conv_pw_13_bn\n",
      "86 conv_pw_13_relu\n",
      "87 global_average_pooling2d_1\n",
      "88 dense_1\n",
      "89 dense_2\n",
      "90 dense_3\n",
      "91 dense_4\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(model.layers):\n",
    "  print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False\n",
    "# or if we want to set the first 20 layers of the network to be non-trainable\n",
    "#for layer in model.layers[:20]:\n",
    "#    layer.trainable=False\n",
    "#for layer in model.layers[20:]:\n",
    "#    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(preprocessing_function=preprocess_input) #included in our dependencies\n",
    "train_generator=train_datagen.flow_from_directory('/Users/josephineferrandino/Desktop/color_class',\n",
    "#train_generator=train_datagen.flow_from_directory('/Users/josephineferrandino/Desktop/art_DB_get_color/data',\n",
    "                                                 target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 2.6956 - accuracy: 0.1733\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 2.0572 - accuracy: 0.2604\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 1.7245 - accuracy: 0.3889\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 1.5178 - accuracy: 0.4271\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.9075 - accuracy: 0.7396\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 3s 948ms/step - loss: 0.9205 - accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.4764 - accuracy: 0.9200\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2310 - accuracy: 0.9375\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 4s 1s/step - loss: 0.2155 - accuracy: 0.9867\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 5s 2s/step - loss: 0.2503 - accuracy: 0.9271\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "color_model = model.fit_generator(generator=train_generator,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                   epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-20eee7465559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'enter in image you want to predict the category of'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('enter in image you want to predict the category of')\n",
    "img = cv2.resize(img,(320,240))\n",
    "img = np.reshape(img,[1,320,240,3])\n",
    "\n",
    "classes = model.predict(img)\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(color_model, 'baseline_model.pkl')\n",
    "logistic_from_pickle = joblib.load('baseline_model.pkl') \n",
    "#logistic_from_pickle.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
